# Инструкция по скачиванию модели Qwen-Image

## ✅ Рекомендуемый способ (официальные diffusers-веса)

**Используйте официальную модель `Qwen/Qwen-Image` через diffusers** - это самый простой и надёжный способ!

```bash
python scripts/download_qwen_image.py
```

См. `docs/MODEL_SETUP.md` для подробностей.

---

## Альтернативный способ (старый)

Модель Qwen-Image должна быть скачана отдельно из официального репозитория Qwen. Скрипт `scripts/download_base_model.py` скачивает только токенайзер и процессор.

## Шаги

### 1. Проверка официального репозитория

Проверьте официальный репозиторий Qwen для получения модели:
- GitHub: https://github.com/QwenLM/Qwen
- Hugging Face: https://huggingface.co/Qwen

### 2. Формат модели

Согласно ТЗ, модель должна быть в облегчённом формате:
- FP8/Q4 смешанные квантизации для экономии VRAM
- Включает веса UNet/MMDiT
- Включает текстовый энкодер
- Включает VAE
- Включает tokenizer.json

### 3. Размещение модели

После скачивания разместите модель в следующей структуре:

```
models/base/
├── unet/              # Веса UNet/MMDiT
├── text_encoder/       # Текстовый энкодер
├── vae/               # VAE
├── tokenizer/         # Токенайзер (будет перезаписан скриптом)
└── model_info.json    # Информация о модели
```

### 4. Обновление конфигурации

Отредактируйте `config.yaml` и укажите правильный путь к модели:

```yaml
base_model:
  name: "models/base"  # или путь к Hugging Face модели
  dtype: "fp8"        # или "fp16", "q4"
```

### 5. Проверка

После размещения модели проверьте загрузку:

```bash
python -c "from src.config import get_config; config = get_config(); print(config.get('base_model.name'))"
```

## Альтернативные варианты

Если модель Qwen-Image 20B недоступна, можно временно использовать:
- Qwen2-VL-7B-Instruct (указана в config.yaml как временная)
- Другие совместимые модели из семейства Qwen

⚠️ **Внимание**: Использование других моделей может потребовать изменений в коде обучения и инференса.

